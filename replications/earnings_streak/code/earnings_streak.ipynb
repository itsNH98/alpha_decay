{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earnings Streak \n",
    "\n",
    "From \"Streaks in Earnings Surprises and the Cross-Section of Stock Returns\" (Loh & Warachka, 2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas_datareader as pdr\n",
    "import quantstats as qs\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathDataIntermediate = '~/Mirror/Work/research/main/investing/equities_investing/anomalies_research/replications/yilin_resources/yilin_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to first of next month to eventually merge with RDQ data \n",
    "def first_day_of_next_month(date):\n",
    "    next_month = date.replace(day=1) + pd.DateOffset(months=1)\n",
    "    return next_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "IBES_EPS_Adj = pd.read_csv(pathDataIntermediate + '/IBES_EPS_Adj.csv')\n",
    "IBES_EPS_Adj['tickerIBES'].fillna('NA', inplace=True)\n",
    "IBES_EPS_Adj = IBES_EPS_Adj.loc[IBES_EPS_Adj['fpi']==6]\n",
    "IBES_EPS_Adj.dropna(subset=['actual', 'meanest','price'], inplace=True)\n",
    "IBES_EPS_Adj = IBES_EPS_Adj[IBES_EPS_Adj['price'] > 5.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'fpi', 'tickerIBES', 'statpers', 'fpedats', 'anndats_act',\n",
       "       'meanest', 'actual', 'medest', 'stdev', 'numest', 'prdays', 'price',\n",
       "       'shout', 'time_avail_m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with Earnings Value\n",
    "# Tickers IBES weird identifier of unknown link to CRSPCOMP\n",
    "IBES_EPS_Adj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual release date as date of availability\n",
    "# Add one to avoid look-ahead bias (this creates availability only at the beginning of next month)\n",
    "# This works in the context of monthly re-allocation \n",
    "IBES_EPS_Adj['time_avail_m'] = pd.to_datetime(IBES_EPS_Adj['anndats_act']).dt.to_period('M') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the last forecast before the actual release to compute surprise\n",
    "IBES_EPS_Adj = IBES_EPS_Adj.sort_values(['tickerIBES', 'time_avail_m','anndats_act','statpers']).reset_index(drop=True)\n",
    "IBES_EPS_Adj = IBES_EPS_Adj.sort_values(['tickerIBES', 'time_avail_m']).drop_duplicates(['tickerIBES', 'time_avail_m'], keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define earnings surprise (positive / negative surprise) and Streak (consistent Surp)\n",
    "IBES_EPS_Adj['earnings_surprise'] = (IBES_EPS_Adj['actual'] - IBES_EPS_Adj['meanest'])/ IBES_EPS_Adj['price']\n",
    "\n",
    "# Lagged earnings surprise\n",
    "IBES_EPS_Adj['past_earnings_surprise'] = IBES_EPS_Adj.groupby(['tickerIBES'])['earnings_surprise'].shift(1)\n",
    "\n",
    "# Defining streak with 0 values\n",
    "IBES_EPS_Adj['positive_earnings_streak'] = 0\n",
    "IBES_EPS_Adj['negative_earnings_streak'] = 0\n",
    "\n",
    "# If sign of streak same as previous surprise, define a streak\n",
    "# If sign negative, define negative streak, otherwise it's a positive streak\n",
    "IBES_EPS_Adj['negative_earnings_streak'].loc[(np.sign(IBES_EPS_Adj['earnings_surprise']) == -1) & (np.sign(IBES_EPS_Adj['earnings_surprise']) == np.sign(IBES_EPS_Adj['past_earnings_surprise']))] = 1\n",
    "IBES_EPS_Adj['positive_earnings_streak'].loc[(np.sign(IBES_EPS_Adj['earnings_surprise']) == 1) & (np.sign(IBES_EPS_Adj['earnings_surprise']) == np.sign(IBES_EPS_Adj['past_earnings_surprise']))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Signal Master to link permno and IBES ticker \n",
    "SignalMasterTable = pd.read_csv(pathDataIntermediate + '/SignalMasterTable.csv',\n",
    "                                usecols = ['permno','time_avail_m','tickerIBES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to monthly\n",
    "SignalMasterTable['time_avail_m'] = pd.to_datetime(SignalMasterTable['time_avail_m']).dt.to_period('M')\n",
    "SignalMasterTable['tickerIBES'].loc[SignalMasterTable['permno']==81191] = 'NA'\n",
    "\n",
    "# Merge many to one to grab the returns \n",
    "df = pd.merge(SignalMasterTable, IBES_EPS_Adj, on=['time_avail_m','tickerIBES'], validate = 'm:1', how='left')\n",
    "\n",
    "# Drop useless columns\n",
    "df.drop(columns=['fpi','tickerIBES'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_m = pd.read_csv('../../yilin_resources/yilin_data/mCRSP.csv', parse_dates=['date'])\n",
    "crsp_m['date'] = crsp_m['date'].dt.to_period('M')\n",
    "crsp_m = crsp_m.rename(columns={'date':'time_avail_m'})\n",
    "df = pd.merge(df, crsp_m[['time_avail_m', 'permno', 'ret']], on=['time_avail_m','permno'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def define_universe(df, file):\n",
    "#     # Load the list of permno values from the text file\n",
    "#     with open(file, 'r') as file:\n",
    "#         permno_list = [int(line.strip()) for line in file]\n",
    "\n",
    "#     # Filter the DataFrame based on permno values\n",
    "#     universe = df[df['permno'].isin(permno_list)]\n",
    "#     return universe\n",
    "\n",
    "# df = define_universe(df, '../resources/sp500_permnos.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop stale or empty\n",
    "df['anndats_act'] = df.groupby(['permno'])['anndats_act'].ffill()\n",
    "df.dropna(subset=['anndats_act'], inplace=True)\n",
    "df['time_avail_m'] = df['time_avail_m'].apply(lambda x: x.to_timestamp())\n",
    "#df = df.drop(df[(df['time_avail_m'] - pd.to_datetime(df['anndats_act']))/np.timedelta64(1,'M')>6].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_ret'] = np.log(1 + df['ret'])\n",
    "\n",
    "df['cumret'] = df.groupby('permno')['log_ret'].shift(-1) + df.groupby('permno')['log_ret'].shift(-2) + df.groupby('permno')['log_ret'].shift(-3) + df.groupby('permno')['log_ret'].shift(-4) + df.groupby('permno')['log_ret'].shift(-5) + df.groupby('permno')['log_ret'].shift(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>time_avail_m</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statpers</th>\n",
       "      <th>fpedats</th>\n",
       "      <th>anndats_act</th>\n",
       "      <th>meanest</th>\n",
       "      <th>actual</th>\n",
       "      <th>medest</th>\n",
       "      <th>stdev</th>\n",
       "      <th>...</th>\n",
       "      <th>prdays</th>\n",
       "      <th>price</th>\n",
       "      <th>shout</th>\n",
       "      <th>earnings_surprise</th>\n",
       "      <th>past_earnings_surprise</th>\n",
       "      <th>positive_earnings_streak</th>\n",
       "      <th>negative_earnings_streak</th>\n",
       "      <th>ret</th>\n",
       "      <th>log_ret</th>\n",
       "      <th>cumret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>1996-05-01</td>\n",
       "      <td>5025529.0</td>\n",
       "      <td>1996-04-18</td>\n",
       "      <td>1995-12-31</td>\n",
       "      <td>1996-04-18</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1996-04-17</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.420</td>\n",
       "      <td>-0.006383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.021277</td>\n",
       "      <td>-0.021506</td>\n",
       "      <td>0.039357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>1996-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.060290</td>\n",
       "      <td>-0.062184</td>\n",
       "      <td>0.040273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>1996-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023167</td>\n",
       "      <td>0.076825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>1996-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.037458</td>\n",
       "      <td>0.039368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>1996-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041765</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>0.010552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879037</th>\n",
       "      <td>93429.0</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.064154</td>\n",
       "      <td>-0.066305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879038</th>\n",
       "      <td>93429.0</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.083817</td>\n",
       "      <td>-0.087539</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879039</th>\n",
       "      <td>93429.0</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2209645.0</td>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.3800</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>109.33</td>\n",
       "      <td>112.666</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066728</td>\n",
       "      <td>0.064596</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879040</th>\n",
       "      <td>93429.0</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.066686</td>\n",
       "      <td>-0.069013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879041</th>\n",
       "      <td>93429.0</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947822 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          permno time_avail_m  Unnamed: 0    statpers     fpedats anndats_act  \\\n",
       "141      10001.0   1996-05-01   5025529.0  1996-04-18  1995-12-31  1996-04-18   \n",
       "142      10001.0   1996-06-01         NaN         NaN         NaN  1996-04-18   \n",
       "143      10001.0   1996-07-01         NaN         NaN         NaN  1996-04-18   \n",
       "144      10001.0   1996-08-01         NaN         NaN         NaN  1996-04-18   \n",
       "145      10001.0   1996-09-01         NaN         NaN         NaN  1996-04-18   \n",
       "...          ...          ...         ...         ...         ...         ...   \n",
       "3879037  93429.0   2018-04-01         NaN         NaN         NaN  2018-02-09   \n",
       "3879038  93429.0   2018-05-01         NaN         NaN         NaN  2018-02-09   \n",
       "3879039  93429.0   2018-06-01   2209645.0  2018-04-19  2018-03-31  2018-05-04   \n",
       "3879040  93429.0   2018-07-01         NaN         NaN         NaN  2018-05-04   \n",
       "3879041  93429.0   2018-08-01         NaN         NaN         NaN  2018-05-04   \n",
       "\n",
       "         meanest  actual  medest  stdev  ...      prdays   price    shout  \\\n",
       "141         0.23  0.1933    0.23    NaN  ...  1996-04-17    5.75    3.420   \n",
       "142          NaN     NaN     NaN    NaN  ...         NaN     NaN      NaN   \n",
       "143          NaN     NaN     NaN    NaN  ...         NaN     NaN      NaN   \n",
       "144          NaN     NaN     NaN    NaN  ...         NaN     NaN      NaN   \n",
       "145          NaN     NaN     NaN    NaN  ...         NaN     NaN      NaN   \n",
       "...          ...     ...     ...    ...  ...         ...     ...      ...   \n",
       "3879037      NaN     NaN     NaN    NaN  ...         NaN     NaN      NaN   \n",
       "3879038      NaN     NaN     NaN    NaN  ...         NaN     NaN      NaN   \n",
       "3879039     1.26  1.3800    1.27   0.04  ...  2018-04-18  109.33  112.666   \n",
       "3879040      NaN     NaN     NaN    NaN  ...         NaN     NaN      NaN   \n",
       "3879041      NaN     NaN     NaN    NaN  ...         NaN     NaN      NaN   \n",
       "\n",
       "         earnings_surprise  past_earnings_surprise  positive_earnings_streak  \\\n",
       "141              -0.006383                     NaN                       0.0   \n",
       "142                    NaN                     NaN                       NaN   \n",
       "143                    NaN                     NaN                       NaN   \n",
       "144                    NaN                     NaN                       NaN   \n",
       "145                    NaN                     NaN                       NaN   \n",
       "...                    ...                     ...                       ...   \n",
       "3879037                NaN                     NaN                       NaN   \n",
       "3879038                NaN                     NaN                       NaN   \n",
       "3879039           0.001098                     0.0                       0.0   \n",
       "3879040                NaN                     NaN                       NaN   \n",
       "3879041                NaN                     NaN                       NaN   \n",
       "\n",
       "         negative_earnings_streak       ret   log_ret    cumret  \n",
       "141                           0.0 -0.021277 -0.021506  0.039357  \n",
       "142                           NaN -0.060290 -0.062184  0.040273  \n",
       "143                           NaN  0.023438  0.023167  0.076825  \n",
       "144                           NaN  0.038168  0.037458  0.039368  \n",
       "145                           NaN  0.041765  0.040916  0.010552  \n",
       "...                           ...       ...       ...       ...  \n",
       "3879037                       NaN -0.064154 -0.066305       NaN  \n",
       "3879038                       NaN -0.083817 -0.087539       NaN  \n",
       "3879039                       0.0  0.066728  0.064596       NaN  \n",
       "3879040                       NaN -0.066686 -0.069013       NaN  \n",
       "3879041                       NaN  0.040976  0.040159       NaN  \n",
       "\n",
       "[947822 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['EarningsStreak'] = df['surp'].copy()\n",
    "# df['EarningsStreak'] = df.groupby(['permno'])['EarningsStreak'].ffill()\n",
    "\n",
    "# df['EarningsStreak'].replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "# df.dropna(subset=['EarningsStreak'], inplace=True)\n",
    "# df = df.reset_index(drop=True)\n",
    "df['time_avail_m'] = df['time_avail_m'].dt.to_period('M')\n",
    "df.rename(columns={'time_avail_m': 'yyyymm'}, inplace = True)\n",
    "df = df[['permno','yyyymm', 'cumret','positive_earnings_streak', 'negative_earnings_streak']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Portfolio and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long and short portfolio\n",
    "L_trades = df[df['positive_earnings_streak'] == 1]\n",
    "S_trades = df[df['negative_earnings_streak'] == 1]\n",
    "\n",
    "L = L_trades.groupby('yyyymm')['cumret'].mean().asfreq('M', fill_value=0)\n",
    "S = S_trades.groupby('yyyymm')['cumret'].mean().asfreq('M', fill_value=0)\n",
    "\n",
    "LS = (L - S).dropna()\n",
    "\n",
    "LS.index = LS.index.to_timestamp()\n",
    "\n",
    "start_date = LS.index.min()\n",
    "end_date = LS.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking with the FF5\n",
    "FF_five_with_rf= pdr.get_data_famafrench('F-F_Research_Data_5_Factors_2x3', start='1900')[0]\n",
    "FF_five = FF_five_with_rf.drop(columns={'RF'}) / 100\n",
    "FF_five.index = FF_five.index.to_timestamp()\n",
    "FF_five = FF_five.loc[(FF_five.index >= start_date) & (FF_five.index <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking with SP500\n",
    "sp500_rets = pd.read_csv('../../resources/sp500_rets.csv')\n",
    "sp500_rets['MthCalDt'] = pd.to_datetime(sp500_rets['MthCalDt'])\n",
    "sp500_rets['MthCalDt'] = sp500_rets['MthCalDt'].apply(first_day_of_next_month)\n",
    "sp500_rets = sp500_rets.set_index('MthCalDt')\n",
    "sp500_rets = sp500_rets.loc[(sp500_rets.index >= start_date) & (sp500_rets.index <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 cumret   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Mon, 28 Aug 2023   Prob (F-statistic):                nan\n",
      "Time:                        23:39:52   Log-Likelihood:                 414.47\n",
      "No. Observations:                 441   AIC:                            -826.9\n",
      "Df Residuals:                     440   BIC:                            -822.8\n",
      "Df Model:                           0                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0538      0.008      7.161      0.000       0.039       0.069\n",
      "==============================================================================\n",
      "Omnibus:                       42.800   Durbin-Watson:                   1.299\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              221.187\n",
      "Skew:                          -0.140   Prob(JB):                     9.33e-49\n",
      "Kurtosis:                       6.458   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 10 lags and without small sample correction\n"
     ]
    }
   ],
   "source": [
    "print(sm.OLS(LS, np.ones_like(LS)).fit(cov_type='HAC', cov_kwds={'maxlags': 10}).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 cumret   R-squared:                       0.012\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     1.020\n",
      "Date:                Mon, 28 Aug 2023   Prob (F-statistic):              0.405\n",
      "Time:                        23:39:52   Log-Likelihood:                 417.24\n",
      "No. Observations:                 441   AIC:                            -822.5\n",
      "Df Residuals:                     435   BIC:                            -797.9\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0560      0.007      7.571      0.000       0.042       0.071\n",
      "Mkt-RF        -0.0813      0.109     -0.747      0.455      -0.294       0.132\n",
      "SMB           -0.3353      0.232     -1.442      0.149      -0.791       0.120\n",
      "HML            0.0900      0.250      0.360      0.719      -0.400       0.581\n",
      "RMW           -0.1993      0.238     -0.838      0.402      -0.665       0.267\n",
      "CMA           -0.3269      0.359     -0.911      0.363      -1.031       0.377\n",
      "==============================================================================\n",
      "Omnibus:                       41.802   Durbin-Watson:                   1.338\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              219.952\n",
      "Skew:                          -0.081   Prob(JB):                     1.73e-48\n",
      "Kurtosis:                       6.456   Cond. No.                         78.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 10 lags and without small sample correction\n"
     ]
    }
   ],
   "source": [
    "print(sm.OLS(LS, sm.add_constant(FF_five)).fit(cov_type='HAC', cov_kwds={'maxlags': 10}).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 cumret   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.5972\n",
      "Date:                Mon, 28 Aug 2023   Prob (F-statistic):              0.440\n",
      "Time:                        23:39:52   Log-Likelihood:                 414.86\n",
      "No. Observations:                 441   AIC:                            -825.7\n",
      "Df Residuals:                     439   BIC:                            -817.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "INDNO       5.476e-08   8.01e-09      6.840      0.000    3.91e-08    7.05e-08\n",
      "MthTotRet     -0.0928      0.120     -0.773      0.440      -0.328       0.143\n",
      "==============================================================================\n",
      "Omnibus:                       42.862   Durbin-Watson:                   1.288\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              217.400\n",
      "Skew:                          -0.159   Prob(JB):                     6.20e-48\n",
      "Kurtosis:                       6.425   Cond. No.                     2.31e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 10 lags and without small sample correction\n",
      "[2] The condition number is large, 2.31e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(sm.OLS(LS, sm.add_constant(sp500_rets)).fit(cov_type='HAC', cov_kwds={'maxlags': 10}).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs.reports.html(LS, benchmark=sp500_rets, rf=0.04, title='Earnings Streak Tearsheet', download_filename='../results/es_tearsheets.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
